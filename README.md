# ðŸ¦™ LM Stud â€“ Local LLMs Minus the Lard

> **TL;DR**  
> A WinForms chat client for `llama.cpp`, `whisper.cpp` and your questionable life choices.  
> **Zero Electron. Zero telemetry. Zero regrets.**

---

## Features

| â˜‘ï¸ | What It Does |
| --- | --- |
| âœ… | Launches in millisecondsâ€”your GPU blinks and itâ€™s already chatting. |
| âœ… | Edit / regenerate / yeet messages. |
| âœ… | Shows the modelâ€™s â€œthinkingâ€ stream (fun for prompt nerds). |
| âœ… | Drag-drop files â†’ instant code blocks. |
| âœ… | One-click Hugging Face search & download. |
| âœ… | **Built-in Google Search + webpage fetch** (super-visible setup below). |
| âœ… | Optional speech I/O with `whisper.cpp`â€”talk smack to your computer. |
| âœ… | Tiny memory footprintâ€”smaller than RGB keyboard driver. |

---

## Google Search â€“ **READ ME FIRST** âš ï¸

```text
1)  Grab an API key
    https://console.cloud.google.com/apis/dashboard
    â†’ new project â†’ enable â€œCustom Search APIâ€ â†’ copy the key.

2)  Create a Search Engine ID
    https://programmablesearchengine.google.com/controlpanel/overview
    â†’ â€œAddâ€ â†’ â€œSearch the entire webâ€ â†’ grab the cx ID.

3)  Paste both values in  Settings â†’ Tools â†’ Google Search.
    Congratsâ€”~100 free queries per day. Abuse responsibly.
```
---

## Screenshots

|             Chat Tab            |               Settings Tab              |              Models Tab             |                Hugging Face Tab               |
| :-----------------------------: | :-------------------------------------: | :---------------------------------: | :-------------------------------------------: |
| ![Chat](./screenshots/Chat.PNG) | ![Settings](./screenshots/Settings.PNG) | ![Models](./screenshots/Models.PNG) | ![Huggingface](./screenshots/Huggingface.PNG) |

---

## Quick-Start Build

```text
> clone https://github.com/CommanderLake/LMStud - obviously
> from a Visual Studio x64 native tools command prompt...
> E:\llama.cpp\build> cmake .. -DGGML_NATIVE=OFF -DGGML_BACKEND_DL=ON -DGGML_NATIVE=OFF -DGGML_AVX2=ON -DGGML_BMI2=ON -DGGML_CUDA=ON -DGGML_CUDA_F16=ON -DLLAMA_CURL=OFF -DLLAMA_ALL_WARNINGS=OFF -DLLAMA_BUILD_TESTS=OFF -DLLAMA_BUILD_TOOLS=OFF -DLLAMA_BUILD_EXAMPLES=OFF -DLLAMA_BUILD_SERVER=OFF
> or whatever bits and bobs you want
> copy common.lib llama.lib ggml.lib ggml-base.lib â†’ $(SolutionDir)\lib\{Debug|Release}
> drop llama.dll, ggml*.dll & whisper.dll into the C# x64 bin folder
> vcpkg install SDL2:x64-windows-static
> vcpkg install curl[openssl]:x64-windows-static
> open LM Stud.sln in Visual Studio
> adjust VC++ Directories in Stud project
> build
```

---

## Settings Cheat-Sheet

| Section                | Knobs & Dials                                                  |
| ---------------------- | -------------------------------------------------------------- |
| **CPU Params / Batch** | Threads, strict pinning, batch threads.                        |
| **Common**             | Context size, GPU layers, temperature, tokens to generate.     |
| **Advanced**           | NUMA strategy, repeat penalty, top-k/p, batch size.            |
| **Voice**              | Model picker, wake word, VAD, frequency threshold, GPU toggle. |
| **Tools**              | Enable Google Search (API key + cx), enable webpage fetch.     |

---

## Contributing

* Fork it.
* Break it.
* PR it.
* Get internet points.
  (Memes optional but encouraged.)

---

## License

MITâ€”short, sweet and almost readable.
